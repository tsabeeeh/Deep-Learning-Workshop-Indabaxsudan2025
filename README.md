# Deep-Learning-Workshop-Indabaxsudan2025
This repository contains the materials for the workshop held as part of Indabaxsudan 2025, focusing on Introduction to Deep Learning. The workshop was designed to provide participants with the fundamentals of deep learning, neural network architectures, and their applications in solving real-world problems.
Deep Learning Workshop â€” Indabaxsudan 2025

### Contents:
1. Introduction to Deep Learning
This section covers the basics of deep learning, including:
What is Deep Learning?
Why "Deep" (Many Layers)?
The architecture of neural networks.
How neural networks learn from data.
2. Understanding Neural Networks
In this section, we break down the components of a neural network:
Inputs, Weights, Bias, and Output:
The role of each in a neural network.
Mathematical explanation of how the neuron functions.
Activation Functions:
Importance of activation functions like ReLU and Sigmoid.
3. Deep Learning From Scratch: A NumPy-Based Neural Network Guide
This guide provides an in-depth look at implementing a neural network from scratch using NumPy. Key topics include:
Logistic Regression (a single neuron).
Shallow Neural Networks.
Understanding Forward Propagation, Backward Propagation (Gradients), and Gradient Descent.
Practical implementation using the make_moons dataset.

### Getting Started
Clone the repository:
Bash
git clone https://github.com/tsabeeeh/Deep-Learning-Workshop-Indabaxsudan2025.git

Alternatively, you can run the notebook directly on Google Colab by clicking the link below:
https://colab.research.google.com/drive/1XylXx5dwf44d_DTzOtRBL81-5ORw7pfd?usp=sharing

### Acknowledgments
This workshop was part of Indabaxsudan 2025 and was created by:

ðŸ”ºTsabeeh Hamed

ðŸ”ºAl-Hassen Sabeeh

ðŸ”ºIbraheem Al-Hafiz

ðŸ”ºRama Abdelgadir

Special thanks to the participants who made this workshop a success!
